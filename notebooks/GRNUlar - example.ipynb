{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRNUlar : A small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, subprocess\n",
    "sys.path.insert(0, '../')\n",
    "# Make all the changes to parameters in the main_grnular_sample file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We train on the Clean data generated from SERGIO\n",
    "### SERGIO params:\n",
    "C = 5 classes, D=100 genes, total_cells=1000, cells per cell type = 200\n",
    "### GRNUlar params: \n",
    "Hidden NN = 40, 2 layer NN, Unroll P=10, Unroll L=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ADD_TECHNICAL_NOISE='no', C=5, D=100, DATA_METHOD='sim_expt', DATA_NAME='DS1', DATA_TYPE='clean', DECAYS=1.0, DNN_EPOCHS=200, EPOCHS=20, GLAD_LOSS='mse_fb', H=3, Hd=40, INIT_DIAG=0, K_test=50, K_train=20, K_valid=20, Kij_max=5.0, Kij_min=1.0, L=15, MODEL_SELECT='aupr', NOISE_PARAMS=0.1, NOISE_TYPE='dpd', P=10, POINTS_PER_CLASS=200, PRINT_EPOCH=20, SAMPLING_STATE=15, SAVE_GRAPHS='yes', SHARED_COOP_STATE=2, USE_CUDA_FLAG=0, USE_TF_NAMES='yes', beta=1.0, connect_TF_prob=0.2, dropout_percentile=82, dropout_shape=6.5, lambda_init=1, lrDNN=0.03, lr_glad=0.03, nF=3, pcr_high_max=1.0, pcr_high_min=0.7, pcr_low_max=0.5, pcr_low_min=0.2, ratio_MR=0.1, sparsity=0.1, theta_init_offset=1, use_optimizer='adam')\n",
      "\n",
      "\n",
      "Reading the input data: Single cell RNA: M(samples) x D(genes) & corresponding C(targets)\n",
      "This should work\n",
      "Filepath:  ../grnular/data/saved_data/KTr20_KVa20_KTe50_D100_C5_Sp0.1_Dtclean_ppc200_SS15_NP0.1_De1.0_NTdpd_SCS2_pcrln0.2_pcrlx0.5_pcrhn0.7_pcrhx1.0_kmin1.0_kmax5.0_rMR0.1_TFp0.2_.pickle\n",
      "Data loaded\n",
      "Training the GLAD model\n",
      "Training phase of grnular: batch\n",
      "CHECK RHO and theta INITIAL:  Parameter containing:\n",
      "tensor([[ 0.3254,  0.1583,  0.3228],\n",
      "        [-0.5641,  0.2645,  0.4420],\n",
      "        [ 0.4604, -0.0760,  0.4955]], requires_grad=True) Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "GLAD model check:  Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "Scheduler milestones:  [10]  gamma = 0.75\n",
      "DNN model check: Sequential(\n",
      "  (0): Linear(in_features=10, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=40, out_features=100, bias=True)\n",
      ")\n",
      "#################### total points =  1000\n",
      "INIT Dnn epoch =  0  Loss DNN:  tensor(1.0417, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  20  Loss DNN:  tensor(0.1577, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  40  Loss DNN:  tensor(0.1257, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  60  Loss DNN:  tensor(0.1143, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  80  Loss DNN:  tensor(0.1087, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  100  Loss DNN:  tensor(0.1048, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  120  Loss DNN:  tensor(0.1017, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  140  Loss DNN:  tensor(0.0992, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  160  Loss DNN:  tensor(0.0971, grad_fn=<MseLossBackward>)\n",
      "INIT Dnn epoch =  180  Loss DNN:  tensor(0.0954, grad_fn=<MseLossBackward>)\n",
      "Dnn epoch =  0  Loss DNN:  tensor([0.1521], grad_fn=<AddBackward0>)\n",
      "Different loss: mse  tensor(0.1040, grad_fn=<MseLossBackward>)  fb tensor(0.8245, grad_fn=<RsubBackward1>)  Balancing r = fb/mse tensor(7.9298)\n",
      "\n",
      " Epoch =  0 Batch =  0  loss glad =  1.7059573\n",
      "Recovery :FDR, TPR, FPR, SHD, nnz_true, nnz_pred, precision, recall, Fb, aupr, auc  0.117 0.548 0.002 65.0 124.0 77.0 0.883 0.548 0.677 0.539 0.774\n",
      "time req for grnular forward call (secs):  0.5475826263427734\n",
      "time req for loss backward call & update (secs):  0.012491941452026367\n",
      "valid: shd Fb accuracy :  174.75 0.804\n",
      "epoch =  10  Updating the best Fb model with valid Fb =  0.804\n",
      "epoch =  10  Updating the best shd model with valid shd =  174.75\n",
      "valid: shd Fb accuracy :  205.7 0.792\n",
      "\n",
      " Epoch =  0 Batch =  1  loss glad =  1.314979\n",
      "Recovery :FDR, TPR, FPR, SHD, nnz_true, nnz_pred, precision, recall, Fb, aupr, auc  0.61 0.905 0.04 207.0 137.0 318.0 0.39 0.905 0.545 0.721 0.944\n",
      "valid: shd Fb accuracy :  150.1 0.796\n",
      "epoch =  10  Updating the best shd model with valid shd =  150.1\n",
      "valid: shd Fb accuracy :  162.25 0.801\n",
      "\n",
      " Epoch =  0 Batch =  2  loss glad =  1.264196\n",
      "Recovery :FDR, TPR, FPR, SHD, nnz_true, nnz_pred, precision, recall, Fb, aupr, auc  0.496 0.946 0.025 128.0 130.0 244.0 0.504 0.946 0.658 0.823 0.969\n",
      "valid: shd Fb accuracy :  226.65 0.786\n",
      "valid: shd Fb accuracy :  216.7 0.778\n",
      "\n",
      " Epoch =  0 Batch =  3  loss glad =  1.3282279\n",
      "Recovery :FDR, TPR, FPR, SHD, nnz_true, nnz_pred, precision, recall, Fb, aupr, auc  0.691 0.95 0.053 261.0 120.0 369.0 0.309 0.95 0.466 0.747 0.967\n",
      "valid: shd Fb accuracy :  135.3 0.789\n",
      "epoch =  10  Updating the best shd model with valid shd =  135.3\n",
      "valid: shd Fb accuracy :  133.55 0.784\n",
      "epoch =  19  Updating the best shd model with valid shd =  133.55\n",
      "\n",
      " Epoch =  0 Batch =  4  loss glad =  1.2021796\n",
      "Recovery :FDR, TPR, FPR, SHD, nnz_true, nnz_pred, precision, recall, Fb, aupr, auc  0.451 0.891 0.018 100.0 119.0 193.0 0.549 0.891 0.679 0.782 0.942\n",
      "valid: shd Fb accuracy :  121.7 0.782\n",
      "epoch =  10  Updating the best shd model with valid shd =  121.7\n",
      "valid: shd Fb accuracy :  97.55 0.757\n",
      "epoch =  19  Updating the best shd model with valid shd =  97.55\n",
      "CHECK RHO & theta Learned, may not correspond to the best metric model:  Parameter containing:\n",
      "tensor([[ 0.3659,  0.1908,  1.1157],\n",
      "        [-0.9671,  0.0424, -0.1281],\n",
      "        [ 0.1151, -0.3619,  0.2679]], requires_grad=True) Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "*****************************************************************************\n",
      "GLAD batch predict results: Number of data pairs Train/valid/test  20 20 50\n",
      "FDR, ,TPR, ,FPR, ,SHD, ,nnz_true, ,nnz_pred, ,precision, ,recall, ,Fb, ,aupr, ,auc, \n",
      "Final results on Training data\n",
      "0.583, 0.061, 0.901, 0.027, 0.033, 0.009, 173.300, 42.083, 123.000, 5.865, 271.900, 42.913, 0.417, 0.061, 0.901, 0.027, 0.567, 0.059, 0.788, 0.046, 0.946, 0.014\n",
      "Final results on Valid data\n",
      "0.592, 0.058, 0.914, 0.025, 0.035, 0.008, 178.300, 41.490, 122.450, 4.904, 279.750, 39.317, 0.408, 0.058, 0.914, 0.025, 0.562, 0.058, 0.796, 0.044, 0.952, 0.014\n",
      "Model trained, now predicting on test data\n",
      "0.591, 0.052, 0.905, 0.025, 0.035, 0.008, 178.320, 40.120, 123.880, 6.173, 278.600, 40.962, 0.409, 0.052, 0.905, 0.025, 0.562, 0.051, 0.798, 0.050, 0.948, 0.013\n"
     ]
    }
   ],
   "source": [
    "%run -i -m 'notebooks.main_grnular_sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above values are mean, std_dev \n",
    "We get around Aupr = 0.798 and Auroc = 0.948 on test data for the clean data setting. We can further improve the results by playing around with GRNUlar parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
